<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html lang="en">

<!-- remove after done debugging!!!! -->
<!-- <meta http-equiv="refresh" content="1" > -->
<!-- remove after done debugging!!!! -->

<head>
  <!-- <meta name=viewport content="width=800"> -->
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    hr {
    border: 0;
    height: 0;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(255, 255, 255, 0.3);
    }

    img {
    border-radius: 5%;
    }

    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 30px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700;
      margin-bottom: 10cm;
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
 
     .zero {
      width: 160px;
      height: 80px;
      position: relative;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    mid {
      font-size: 40px;
      position:relative;
      top:2px;
    }

    span.highlight {
      background-color: #ffffd0;
    }


  #summary:hover + #detail, #detail:hover {
  display: block;
  }
  #detail {
  display: none;
  }

  details summary > * {
    display: inline;
  }
  summary a * {
    pointer-events: none;
    } 
    details summary::-webkit-details-marker {
  display:none;
}
  </style>
  <link rel="icon" href="misc/s_favicon.png">

  <title>Tanmay Shankar</title>
  
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
</head>
<body>

  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody><tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <td width="75%" valign="middle">
              <p align="center">
                <name>Tanmay Shankar</name>
                <!-- <name>Tanmay Shankar <mid><font color=#FF0000>|</font></mid> <font color=#C0C0C0>Suddhu</font></name> -->
              <p align="center">
                <font size="3">tshankar <font color=#FF0000>[at]</font> cs <font color=#FF0000>[dot]</font> cmu <font color=#FF0000>[dot]</font> edu </font>
              </p>
              <p><p style = "text-align:justify">I'm a PhD candidate in the <A href="http://www.ri.cmu.edu/" target="_blank">Robotics Institute</A> at <A href="http://www.cmu.edu" target="_blank"> Carnegie Mellon University</A>,
                 where I work with <A href="https://www.cs.cmu.edu/~./jeanoh/" target="_blank">Jean Oh</a>. Before that, I was a research engineer at Facebook AI Research, Pittsburgh. Before <i>that</i>, I completed my MS in Robotics from the RI too! 
              </p>
              <p><p style = "text-align:justify"> I completed my Masters in Robotics at CMU working with <A href="https://www.cs.cmu.edu/~kaess/" target="_blank">Michael Kaess</a> on visual localization and active exploration for AUVs (<A href="data/papers/Suresh19Thesis.pdf" target="_blank">thesis</a>).
                Prior to that, I worked with <A href="https://frc.ri.cmu.edu/~red/" target="_blank">Red Whittaker</a> on state-estimation for lunar rovers, and spent time at <A href="https://www.iisc.ac.in/">IISc Bangalore</a> working on visual understanding.
                I did my undergrad at IIT Guwahati, where I worked on reinforcement learning networks. 
              </p>

              <p align=center>
                <strong>
                <a href="misc/CV_Suddhu.pdf" target="_blank">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=xYC738YAAAAJ&hl=en" target="_blank">Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/suddhu/" target="_blank"> Github </a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/sudharshansuresh/" target="_blank"> LinkedIn </a>
                </strong>
              </p>
            </td>
            <td width="50%">
              <img src="misc/suddhu-headshot.jpg" style="width: 200; height: auto; border-radius: 5%;">
            </td>
          </tr>
        </table>

        <hr>

        <h1>Updates</h1>          
        <table width="100%" align="center" border="0" cellspacing="6" cellpadding="0">
          <colgroup>
            <col span="1" style="width: 12%;">
            <col span="1" style="width: 88%;">
         </colgroup>
          <tbody>
              <tr>
                  <td><p style="color:FF0000; display:inline;">[Oct '22] &nbsp</p></td>
                  <td>Successfully passed my Ph.D. thesis proposal!</td>
              </tr>
              <tr>
                <td><p style="color:FF0000; display:inline">[Sep '22] &nbsp</p></td>
                <td><a href="https://suddhu.github.io/midastouch-tactile/">MidasTouch</a> was accepted to <a href="https://corl2022.org/">CoRL 2022</a> as an oral. 
                </td>
              </tr>
              <tr>
                <td><p style="color:FF0000; display:inline">[Aug '22] &nbsp</p></td>
                <td>We've extended <a href="https://joeaortiz.github.io/iSDF/">iSDF</a> for neural mapping with the Franka robot, code <a href="https://github.com/facebookresearch/iSDF#3-running-isdf-with-a-franka-and-live-camera-in-ros">here</a>.</td>
              </tr>
              <tr>
                <td><p style="color:FF0000; display:inline">[May '22] &nbsp &nbsp</p></td>
                <td>Organized the <a href="https://www.roboticsdebates.org/">Debates on the Future of Robotics Research workshop</a> at ICRA '22 </td>
              </tr>
              <tr>
                <td><p style="color:FF0000; display:inline">[April '22] &nbsp &nbsp</p></td>
                <td>Spending the summer at <a href="https://ai.facebook.com/">Meta AI</a> with <a href="https://www.mustafamukadam.com/publications">Mustafa Mukadam</a> working on tactile perception/SLAM!</td>
              </tr>
              <tr>
                <td><p style="color:FF0000; display:inline">[Jan '22] &nbsp &nbsp</p></td>
                <td><a href="https://arxiv.org/abs/2109.09884">ShapeMap 3-D</a> was accepted to ICRA 2022, with an open-source <a href="https://github.com/rpl-cmu/shape-map-3D">implementation</a>.</td>
              </tr>
          </tbody>
        </tbody></table>
        </div>
        <br>
        <hr>
        
        <div style="height:20px;font-size:1px;">&nbsp;</div>

        <!-- Research -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
          <tr>
            <td width="100%" valign="middle">
              <h1>Research</h1>
            </td>
          </tr>
        </table>    

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">

    <!-- MidasTouch -->
    <tr>
      <td width="25%" align="center">
        <img src='https://suddhu.github.io/midastouch-tactile/img/midastouch.gif' width="200">
      </td>
      <td valign="center" width="70%">
        <div id="summary">
            <papertitle>
              MidasTouch: Monte-Carlo inference over distributions across sliding touch
            </papertitle>                   
            <div style="height:5px;font-size:1px;">&nbsp;</div>
            <u>S. Suresh</u>,
            <a href="https://si-lynnn.github.io/" target="_blank">Z. Si</a>,
            <a href="https://www.linkedin.com/in/stuartoanderson" target="_blank">S. Anderson</a>,
            <a href="https://www.cs.cmu.edu/~kaess/" target="_blank">M. Kaess</a>, and
            <a href="https://www.mustafamukadam.com/" target="_blank">M. Mukadam</a>
            <div style="height:5px;font-size:1px;">&nbsp;</div>
            <font color=#696969><em>Proc. Conf. on Robot Learning, CoRL</em>, Dec 2022 (to appear)</font>
            <div style="height:5px;font-size:1px;">&nbsp;</div>
            [<font color=#009933>Oral: 6% acceptance rate</font>]
            <div style="height:5px;font-size:1px;">&nbsp;</div>
            <a href="https://arxiv.org/abs/2210.14210"  target="_blank">paper</a> /
            <a href="https://suddhu.github.io/midastouch-tactile/" target="_blank"><b>website</b></a> /
            <a href="https://github.com/facebookresearch/MidasTouch" target="_blank">code</a> /
            <a href="https://youtu.be/L-h8t9-iSFE" target="_blank">presentation</a>
            <div style="height:15px;font-size:1px;">&nbsp;</div>
          </div>
          <div id="detail">
          <i>
            Tracking the pose distribution of a robot finger on an object surface over time, using surface geometry captured by a tactile sensor
          </div>
      </td>
  </tr>

  <!-- ShapeMap3D -->
    <tr>
          <td width="25%" align="center">
            <img src='data/media/shape_map/shape_map.gif' width="200">
          </td>
          <td valign="center" width="70%">
            <div id="summary"> 
                <papertitle>
                  ShapeMap 3-D: Efficient shape mapping through dense touch and vision
                </papertitle>                   
                <div style="height:5px;font-size:1px;">&nbsp;</div>
                <u>S. Suresh</u>,
                <a href="https://si-lynnn.github.io/" target="_blank">Z. Si</a>,
                <a href="https://frostlab.byu.edu/directory/joshua-mangelson" target="_blank">J. Mangelson</a>,
                <a href="http://robotouch.ri.cmu.edu/yuanwz/" target="_blank">W. Yuan</a>, and
                <a href="https://www.cs.cmu.edu/~kaess/" target="_blank">M. Kaess</a>
                <div style="height:5px;font-size:1px;">&nbsp;</div>
                <font color=#696969><em>IEEE Intl. Conf. on Robotics and Automation, ICRA</em>, May 2022</font>
                <div style="height:5px;font-size:1px;">&nbsp;</div>
                <a href="https://arxiv.org/abs/2109.09884"  target="_blank">paper</a> /
                <a href="https://www.cs.cmu.edu/~sudhars1/shape-map/" target="_blank"><b>website</b></a> /
                <a href="https://github.com/rpl-cmu/shape-map-3D" target="_blank">code</a> /
                <a href="https://youtu.be/y3uCoj7qOgA" target="_blank">presentation</a>
                <div style="height:15px;font-size:1px;">&nbsp;</div>
            </div>
            <div id="detail">
              <i>Can we efficiently reconstruct household objects with touch and vision?</i> We harness the GelSight sensor and a depth-camera for 3-D shape perception, as inference on a spatial graph informed by a Gaussian process.
            </div>
            </td>
      </tr>
      
      <!-- tactile slam -->
      <tr>
            <td width="25%" align="center">
              <img src='data/media/contact_slam/sim_result.gif' width="200">
            </td>
            <td valign="center" width="70%">
              <div id="summary">
                  <papertitle>
                    Tactile SLAM: Real-time inference of shape and pose from planar pushing
                  </papertitle>                   
                  <div style="height:5px;font-size:1px;">&nbsp;</div>
                  <u>S. Suresh</u>,
                  <a href="http://web.mit.edu/bauza/www/" target="_blank">M. Bauza</a>,
                  <a href="http://people.csail.mit.edu/peterkty/" target="_blank">K.-T. Yu</a>,
                  <a href="https://frostlab.byu.edu/directory/joshua-mangelson" target="_blank">J. Mangelson</a>,
                  <a href="https://meche.mit.edu/people/faculty/ALBERTOR@MIT.EDU" target="_blank">A. Rodriguez</a>, and
                  <a href="https://www.cs.cmu.edu/~kaess/" target="_blank">M. Kaess</a>
                  <div style="height:5px;font-size:1px;">&nbsp;</div>
                  <em>IEEE Intl. Conf. on Robotics and Automation, ICRA</em>, May 2021 
                  <div style="height:5px;font-size:1px;">&nbsp;</div>
                  [<font color=#009933>Finalist for the 2021 IEEE ICRA Best Paper Award in Service Robotics</font>]
                  <div style="height:5px;font-size:1px;">&nbsp;</div>
                  <a href="https://arxiv.org/abs/2011.07044"  target="_blank">paper</a> /
                  <a href="https://www.cs.cmu.edu/~sudhars1/tactile-slam/" target="_blank"><b>website</b></a> /
                  <a href="https://youtu.be/77VnwArHOhk" target="_blank">presentation</a>
                  <div style="height:15px;font-size:1px;">&nbsp;</div>
                  <div style="height:10px;font-size:1px;">&nbsp;</div>
                </div>
                <div id="detail">
                <i>Can we estimate object shape and pose in real-time through purely tactile sensing?</i> We demonstrate this for planar pushing, combining Gaussian process implicit surfaces with factor-graph based inference.
                </div>
            </td>
        </tr>

        <!-- active slam -->
        <tr>
          <td width="25%" align="center">
            <img src='data/media/active_sal/active.gif' width="200">
          </td>
          <td valign="center" width="70%">
            <div id="summary">
                <papertitle>
                  Active SLAM using 3D submap saliency for underwater volumetric exploration
                </papertitle>

                  <div style="height:5px;font-size:1px;">&nbsp;</div>
                  <u>S. Suresh</u>,
                  <a href="https://www.cs.cmu.edu/~psodhi/" target="_blank">P. Sodhi</a>, 
                  <a href="http://robots.engin.umich.edu/~joshuagm/" target="_blank">J. Mangelson</a>, 
                  <a href="https://frc.ri.cmu.edu/~dsw/info/Home.html" target="_blank">D. Wettergreen</a>, and
                  <a href="https://www.cs.cmu.edu/~kaess/" target="_blank">M. Kaess</a>
                  <div style="height:5px;font-size:1px;">&nbsp;</div>
                  <em>IEEE Intl. Conf. on Robotics and Automation, ICRA</em>, May 2020
                  <div style="height:10px;font-size:1px;">&nbsp;</div>
                  <a href="http://www.cs.cmu.edu/~kaess/pub/Suresh20icra.pdf" target="_blank">paper</a> /
                  <a href="https://youtu.be/4HgdWJlL8JY" target="_blank">presentation</a>
                  <div style="height:10px;font-size:1px;">&nbsp;</div>              
            </div>
            <div id="detail">
                <i>How do you balance volumetric exploration and pose uncertainty in exploration?</i> We combine a sampling-based planner, deformable pose graph, and a 3D saliency metric to explore a 3D underwater volume.
            </div>
          </td>
        </tr>

        <!-- refr slam -->
        <tr>
          <td width="30%" align="center">
            <img src='data/media/refr_slam/refr2.gif'  width="200" height="100">
            <div style="height:3px;font-size:1px;">&nbsp;</div>
            <img src='data/media/refr_slam/refr1.gif'  width="200" height="80">
          </td>
          <td valign="center" width="75%">
            <div id="summary">
                <papertitle>
                  Through-water stereo SLAM with refraction correction for AUV localization
                </papertitle>

                <div style="height:5px;font-size:1px;">&nbsp;</div>
                <u>S. Suresh</u>,
                <a href="https://www.ri.cmu.edu/ri-people/eric-westman/" target="_blank">E. Westman</a>, and
                <a href="https://www.cs.cmu.edu/~kaess/" target="_blank">M. Kaess</a>
                <div style="height:5px;font-size:1px;">&nbsp;</div>
                <em>IEEE Robotics and Automation Letters (RA-L), presented at ICRA 2019</em>, Jan 2019
                <div style="height:10px;font-size:1px;">&nbsp;</div>
                <a href="http://www.cs.cmu.edu/~kaess/pub/Suresh19ral.pdf" target="_blank">paper</a> /
                <a href="https://youtu.be/fZZTDyLymBs" target="_blank">presentation</a>
                <div style="height:10px;font-size:1px;">&nbsp;</div>              
              </div>
              <div id="detail">
              <i>How can you incorporate refraction into water-to-air visual SLAM?</i> We present a novel method inspired by multimedia photogrammetry for underwater localization.
              </div>
          </td>
        </tr>

        <!-- doe -->
        <tr>
           <td width="25%" align="center">
            <img src='data/media/doe/test.gif'   width="200" height="100">
            <div style="height:3px;font-size:1px;">&nbsp;</div>
            <img src='data/media/doe/checker.gif'   width="200" height="80">
          </td>
          <td valign="center" width="75%">
            <div id="summary">
                <papertitle>
                  Localized imaging and mapping for underwater fuel storage basins 
                </papertitle>
                <div style="height:5px;font-size:1px;">&nbsp;</div>
                J. Hsiung,
                A. Tallaksen,
                L. Papincak,
                <u>S. Suresh</u>,
                H. Jones,
                <a href="https://frc.ri.cmu.edu/~red/" target="_blank">W. L. Whittaker</a>, and
                <a href="https://www.cs.cmu.edu/~kaess/" target="_blank">M. Kaess</a>
                <div style="height:5px;font-size:1px;">&nbsp;</div>
                <em>Proceedings of the Symposium on Waste Management, Phoenix, Arizona</em>, Mar 2018
                <div style="height:10px;font-size:1px;">&nbsp;</div>
                <a href="data/papers/wm18_final.pdf" target="_blank">paper</a> /
                <a href="data/papers/wm18_presentation.pdf" target="_blank">slides</a> /
                <a href="https://www.youtube.com/watch?v=R6JUAJq4rE4&feature=youtu.be" target="_blank">video</a>
                <div style="height:10px;font-size:1px;">&nbsp;</div>        
              </div>
            <div id="detail">
            <i>What's the ideal sensor suite for underwater dense mapping?</i> We build and demonstrate an inspection solution comprising of a stereo camera, IMU, standard + structured lighting, and depth sensor.
            </div>
          </td>
        </tr>

        <!-- riss -->
        <tr>
           <td width="25%" align="center">
            <img src='data/media/riss/autokrawler.gif'   width="200" height="100">
            <div style="height:3px;font-size:1px;">&nbsp;</div>
            <img src='data/media/riss/est.gif'  width="200" height="80">
          </td>
          <td valign="center" width="75%">
            <div id="summary">
                <papertitle>
                  Camera-Only Kinematics for Small Lunar Rovers 
                </papertitle>
                <div style="height:5px;font-size:1px;">&nbsp;</div>
                <u>S. Suresh</u> ,
                <a href="https://www.ri.cmu.edu/ri-people/eugene-fang/" target="_blank">E. Fang</a>,
                and
                <a href="https://frc.ri.cmu.edu/~red/" target="_blank">W. L. Whittaker</a> 
                <div style="height:5px;font-size:1px;">&nbsp;</div>
                <em>Robotics Institute Summer Scholars Working Paper Journal</em>, Nov 2016
                <br> 

                <em>Annual Meeting of the Lunar Exploration Analysis Group</em>, Nov 2016
                <div style="height:10px;font-size:1px;">&nbsp;</div>
                <a href="data/papers/RISS2016.pdf" target="_blank">paper</a> /
                <a href="https://youtu.be/-D7WXVTPXuo" target="_blank">video</a> / 
                <a href="https://www.hou.usra.edu/meetings/leag2016/eposter/5026.pdf" target="_blank">poster</a>
                <div style="height:10px;font-size:1px;">&nbsp;</div>   
              </div>
            <div id="detail">
            <i>Is it possible to track a lunar rover's kinematic state through self-perception?</i> With a downward-facing fisheye lens, we estimate the Autokrawler's kinematics on rugged terrain.
            </div>
          </td>
        </tr>

        <!-- val -->
        <tr>
          <td width="25%" align="center">
            <img src='data/media/iisc/scanpaths.gif'   width="200"  height="120">
          </td>
          <td valign="center" width="75%">
            <div id="summary">
                <papertitle>
                  Object category understanding via eye fixations on freehand sketches
                </papertitle>
                <div style="height:5px;font-size:1px;">&nbsp;</div>
                <a href="https://ravika.github.io/index.html" target="_blank">R. K. Sarvadevabhatla</a>,
                <u>S. Suresh</u> and
                <a href="http://cds.iisc.ac.in/faculty/venky/" target="_blank">R. V. Babu</a>
                <div style="height:5px;font-size:1px;">&nbsp;</div>
                <em>IEEE Transactions on Image Processing (TIP)</em>, May 2017
                <div style="height:10px;font-size:1px;">&nbsp;</div>
                <a href="https://arxiv.org/pdf/1703.06554.pdf" target="_blank">paper</b></a> /
                <a href="http://val.cds.iisc.ac.in/sketchfix/" target="_blank"><b>website</b></a> /
                <a href="https://www.dropbox.com/s/zook724xg256x27/SketchFix-160.zip?dl=0" target="_blank">dataset</a>
                <div style="height:10px;font-size:1px;">&nbsp;</div>
            </div>
            <div id="detail">
            <i>Can we better understand free-hand sketches through human gaze fixations?</i> We collect the <a href="http://val.cds.iisc.ac.in/sketchfix/" target="_blank">SketchFix-160</a> dataset and investigate visual saliency to reveal multi-level consistency in sketches. 
            </div>
          </td>
        </tr>
        </table>
    
    <br>
    <div style="height:20px;font-size:1px;">&nbsp;</div>

    <hr>
    <br>

    <!-- Projects -->
    <h2>Other projects</h2>
      <table width="90%" align="center" border="0" cellspacing="0" cellpadding="10">
          <!-- iSDF-->
          <tr>
            <td width="5%" align="center">
              <img src='https://raw.githubusercontent.com/facebookresearch/iSDF/main/.github/realsense_franka.gif' width="130" height="70">
            </td>
            <td valign="center" width="95%">
                <div id="summary">
                <papertitle>Franka iSDF: neural mapping for tabletop scenes</papertitle> 
                <br>
                <div style="height:3px;font-size:1px;">&nbsp;</div>
                S. Suresh, J. Ortiz, and M. Mukadam 
                <div style="height:3px;font-size:1px;">&nbsp;</div>
                <a href="https://github.com/facebookresearch/iSDF#3-running-isdf-with-a-franka-and-live-camera-in-ros"  target="_blank">github</a>
                <div style="height:3px;font-size:1px;">&nbsp;</div>
                </div>
                <div id="detail">
                <i>Extending iSDF to build real-time neural models of tabletop scenes with the Franka Panda arm</i>
                </div>
            </td>
          </tr>
        <!-- Deepgeo-->
          <tr>
            <td width="5%" align="center">
              <img src='data/media/course-projects/deepgeo.gif' width="100" height="100">
            </td>
            <td valign="center" width="95%">
                <div id="summary">
                <papertitle>DeepGeo: photo localization with deep neural network</papertitle> 
                <br>
                <div style="height:3px;font-size:1px;">&nbsp;</div>
                S. Suresh, N. Chodosh, and M. Abello 
                <div style="height:3px;font-size:1px;">&nbsp;</div>
                <a href="https://arxiv.org/abs/1810.03077"  target="_blank">arXiv</a> / <a href="https://github.com/suddhu/DeepGeo"  target="_blank">github</a>
                <div style="height:3px;font-size:1px;">&nbsp;</div>
                </div>
                <div id="detail">
                <i>A deep network that beats humans at <a href="https://geoguessr.com/" target="_blank">GeoGuessr</a>, trained on our <i>50States10K</i> dataset.</i>
                </div>
            </td>
          </tr>
  
          <!-- TAMP -->
          <tr>
            <td width="5%" align="center">
                <img src='data/media/course-projects/tamp.gif' width="100" height="100">
              </td>
            <td valign="center" width="95%">
                <div id="summary">
                <papertitle>Task and motion planning for robotic food preparation</papertitle> 
                <br>
                <div style="height:3px;font-size:1px;">&nbsp;</div>
                S. Suresh, T. Rhodes, M. Abello, and H. Yadav
                <div style="height:3px;font-size:1px;">&nbsp;</div>
                <a href="data/media/course-projects/TAMP4ParfaitsReport.pdf" target="_blank">pdf</a> /
                <a href="https://www.youtube.com/watch?v=VBhGjcgPVqA" target="_blank">video 1</a> / <a href="https://www.youtube.com/watch?v=BADt_yy_Lvw" target="_blank">video 2</a>
                <div style="height:3px;font-size:1px;">&nbsp;</div>
                </div>
                <div id="detail">
                <i>Hierarchical task and motion planning for a 6-DOF robot arm, to prepare yogurt parfaits!</i>
                </div>
            </td>
          </tr>
  
          <!-- thin structures -->
          <tr>
              <td width="5%" align="center">
                  <img src='data/media/course-projects/thin.gif' width="100" height="100">
            </td>
            <td valign="center" width="95%">
                <div id="summary">
                <papertitle>Thin structure reconstruction via 3D lines and points 
                  </papertitle> 
                  <br>
                  <div style="height:3px;font-size:1px;">&nbsp;</div>
                  S. Suresh and M. Abello
                  <div style="height:3px;font-size:1px;">&nbsp;</div>
                  <a href="data/media/course-projects/LinesPointsSFM.pdf" target="_blank">poster</a>
                  <div style="height:3px;font-size:1px;">&nbsp;</div>
                  </div>
                  <div id="detail">
                  <i>Reconstructing thin objects in a scene through an SfM pipeline can be hard!</i>
                  </div>
            </td>
          </tr>
  
          <!-- dyn param -->
          <tr>
              <td width="5%" align="center">
                <img src='data/media/course-projects/dynparam.png' width="100">
            </td>
            <td valign="center" width="95%">
                <div id="summary">
                <papertitle>Factor graph optimization for dynamic parameter estimation 
                  </papertitle> 
                  <br>
                  <div style="height:3px;font-size:1px;">&nbsp;</div>
                  S. Suresh, E. Dexheimer, and M. Abello
                  <div style="height:3px;font-size:1px;">&nbsp;</div>
                  <a href="data/papers/16-711_final.pdf" target="_blank">pdf</a>
                  <div style="height:3px;font-size:1px;">&nbsp;</div>
                  </div>
                  <div id="detail">
                  <i>We implement a method for estimation of MAV poses and dynamic parameters during flight.</i>
                  </div>
            </td>
          </tr>
      </table>
    
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td>
        <p align="right"><font size="2" color=#696969>
    Last updated: Oct 2022
        <p align="right"><font size="2" color=#696969>
<a href="http://www.cs.berkeley.edu/~barron/" target="_blank"><font size="2">Imitation is the highest form of flattery
</a>
</font></p>

<script type="text/javascript">
  var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
  document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
  try {
    var pageTracker = _gat._getTracker("UA-7580334-1");
    pageTracker._trackPageview();
  } catch (err) {}
</script>
</td></tr>
</table>

</body></html>